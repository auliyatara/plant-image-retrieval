{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hi_detect_low_contrast.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhFjg6x7yOhPaELKY5hEcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auliyatara/plant-image-retrieval/blob/main/tugas5/hi_detect_low_contrast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDj7KnyUJDmp",
        "outputId": "280c9f17-50fd-415c-ad75-1f5242435c46"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEWkiukzJKBT"
      },
      "source": [
        "# Definisikan path kaggle json\n",
        "# Sesuaikan dengan path anda\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Tugas5tkc/Tugas5\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WuLpynfJcMT",
        "outputId": "948dd947-3e73-4467-8dfb-6ff5ec805f7c"
      },
      "source": [
        "# Ubah lokasi direktori kerja\n",
        "# Sesuaikan dengan path anda\n",
        "%cd /content/drive/My Drive/Tugas5tkc/Tugas5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Tugas5tkc/Tugas5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWnyYB2nJfw8",
        "outputId": "e2d23a11-1921-4dbd-cf30-b796fb6193e4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MO1_vk_JiWU",
        "outputId": "3ecf105f-eff3-466f-844e-2fd4fc20b598"
      },
      "source": [
        "!kaggle datasets download -d smaranjitghose/corn-or-maize-leaf-disease-dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading corn-or-maize-leaf-disease-dataset.zip to /content/drive/My Drive/Tugas5tkc/Tugas5\n",
            " 98% 157M/161M [00:01<00:00, 99.3MB/s]\n",
            "100% 161M/161M [00:01<00:00, 103MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyz0pqnLJmQz",
        "outputId": "a091dd5a-6060-4934-8cac-b1ff4d4ff2ec"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corn-or-maize-leaf-disease-dataset.zip\tdata  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBGGEXEsKsBT",
        "outputId": "8ffc4bf7-4be7-4bff-cf19-890fd97126a1"
      },
      "source": [
        "# Cek isi direktori kerja untuk memastikan dataset telah berhasil diekstrak.\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corn-or-maize-leaf-disease-dataset.zip\tdata  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqm-CH73LEmS",
        "outputId": "8fa38efb-b143-42b5-eebe-4db1f822128b"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blight\tCommon_Rust  Gray_Leaf_Spot  Healthy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipoVh7F3LI4p",
        "outputId": "b5f30c0a-4734-4db5-86b9-3877edeccfee"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVSx-dkoLKW5"
      },
      "source": [
        "# import the necessary packages\n",
        "from skimage.exposure import is_low_contrast\n",
        "from imutils.paths import list_images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko2gyNOJLPsh"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1CFzl7sLTXe"
      },
      "source": [
        "# # construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-i\", \"--input\", required=True,\n",
        "# \thelp=\"path to input directory of images\")\n",
        "# ap.add_argument(\"-t\", \"--thresh\", type=float, default=0.35,\n",
        "# \thelp=\"threshold for low contrast\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"input\": \"examples\",\n",
        "    \"thresh\": 0.35\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SpVAi5zLWhG"
      },
      "source": [
        "# grab the paths to the input images\n",
        "imagePaths = sorted(list(list_images(args[\"input\"])))\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# load the input image from disk, resize it, and convert it to\n",
        "\t# grayscale\n",
        "\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "\t\tlen(imagePaths)))\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = imutils.resize(image, width=450)\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\t# blur the image slightly and perform edge detection\n",
        "\tblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\tedged = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "\t# initialize the text and color to indicate that the input image\n",
        "\t# is *not* low contrast\n",
        "\ttext = \"Low contrast: No\"\n",
        "\tcolor = (0, 255, 0)\n",
        "\n",
        "\t# check to see if the image is low contrast\n",
        "\tif is_low_contrast(gray, fraction_threshold=args[\"thresh\"]):\n",
        "\t\t# update the text and color\n",
        "\t\ttext = \"Low contrast: Yes\"\n",
        "\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t# otherwise, the image is *not* low contrast, so we can continue\n",
        "\t# processing it\n",
        "\telse:\n",
        "\t\t# find contours in the edge map and find the largest one,\n",
        "\t\t# which we'll assume is the outline of our color correction\n",
        "\t\t# card\n",
        "\t\tcnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcnts = imutils.grab_contours(cnts)\n",
        "\t\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t\t# draw the largest contour on the image\n",
        "\t\tcv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
        "\n",
        "\t# draw the text on the output image\n",
        "\tcv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
        "\t\tcolor, 2)\n",
        "\n",
        "\t# show the output image and edge map\n",
        "\tplt_imshow(\"Image\", image)\n",
        "\tplt_imshow(\"Edge\", edged)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj4NpMf_Lb9e"
      },
      "source": [
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"input\": \"example_video.mp4\",\n",
        "    \"thresh\": 0.35,\n",
        "    \"output\": \"output.avi\"\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1GLKtqEL06V",
        "outputId": "3304e7f1-c439-4a61-f752-b8e77dca5678"
      },
      "source": [
        "# grab a pointer to the input video stream and and initialize pointer \n",
        "# to output file\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs = cv2.VideoCapture(args[\"input\"] if args[\"input\"] else 0)\n",
        "writer = None\n",
        "\n",
        "# loop over frames from the video stream\n",
        "while True:\n",
        "\t# read a frame from the video stream\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\n",
        "\t# if the frame was not grabbed then we've reached the end of\n",
        "\t# the video stream so exit the script\n",
        "\tif not grabbed:\n",
        "\t\tprint(\"[INFO] no frame read from stream - exiting\")\n",
        "\t\tbreak\n",
        "\n",
        "\t# resize the frame, convert it to grayscale, blur it, and then\n",
        "\t# perform edge detection\n",
        "\tframe = imutils.resize(frame, width=450)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\tblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\tedged = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "\t# initialize the text and color to indicate that the current\n",
        "\t# frame is *not* low contrast\n",
        "\ttext = \"Low contrast: No\"\n",
        "\tcolor = (0, 255, 0)\n",
        "\n",
        "\t# check to see if the frame is low contrast, and if so, update\n",
        "\t# the text and color\n",
        "\tif is_low_contrast(gray, fraction_threshold=args[\"thresh\"]):\n",
        "\t\ttext = \"Low contrast: Yes\"\n",
        "\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t# otherwise, the frame is *not* low contrast, so we can continue\n",
        "\t# processing it\n",
        "\telse:\n",
        "\t\t# find contours in the edge map and find the largest one,\n",
        "\t\t# which we'll assume is the outline of our color correction\n",
        "\t\t# card\n",
        "\t\tcnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcnts = imutils.grab_contours(cnts)\n",
        "\t\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t\t# draw the largest contour on the frame\n",
        "\t\tcv2.drawContours(frame, [c], -1, (0, 255, 0), 2)\n",
        "\n",
        "\t# draw the text on the output frame\n",
        "\tcv2.putText(frame, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
        "\t\tcolor, 2)\n",
        "\n",
        "\t# stack the output frame and edge map next to each other\n",
        "\toutput = np.dstack([edged] * 3)\n",
        "\toutput = np.hstack([frame, output])\n",
        "\n",
        "    # if the video writer is None *AND* we are supposed to write\n",
        "\t# the output video to disk initialize the writer\n",
        "\tif writer is None and args[\"output\"] is not None:\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
        "\t\t\t(output.shape[1], output.shape[0]), True)\n",
        "  \n",
        "    # if the writer is not None, write the frame to disk\n",
        "\tif writer is not None:\n",
        "\t\twriter.write(output)\n",
        "  \n",
        "# do a bit of cleanup\n",
        "vs.release()\n",
        "vs.release()\n",
        "\n",
        "# check to see if the video writer point needs to be released\n",
        "if writer is not None:\n",
        "\twriter.release()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] accessing video stream...\n",
            "[INFO] no frame read from stream - exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PndoUeegL6mM",
        "outputId": "b334a804-3da5-4268-c285-fc07f4d35504"
      },
      "source": [
        "!ffmpeg -i \"output.avi\" output.mp4"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[1;31moutput.avi: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "qWvGHiCwL_2M",
        "outputId": "a19820a2-e768-46b4-c7b9-18fd88fa9878"
      },
      "source": [
        "#@title Display video inline\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(\"output.mp4\", \"rb\").read()\n",
        "dataURL = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=700 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % dataURL)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-bd6498df6b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbase64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdataURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:video/mp4;base64,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m HTML(\"\"\"\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output.mp4'"
          ]
        }
      ]
    }
  ]
}